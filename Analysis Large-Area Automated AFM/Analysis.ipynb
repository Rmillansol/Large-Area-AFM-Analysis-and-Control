{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Analysis Notebook\n",
    "\n",
    "**Author**: Ruben Millan-Solsona  \n",
    "**Date**: 2024-11-10 \n",
    "\n",
    "This notebook contains functions to prepare and flatten images for stitching in AFM analysis, using both automatic and manual methods. It includes tools for saving and normalizing images for further analysis.  \n",
    "**Sections**:\n",
    "1. **Import Statements and Setup**: Required modules and classes.\n",
    "2. **Auto-Flatting for Stitch Preparation**: Automatically flattens images and generates masks using threshold-based adjustments.\n",
    "3. **Manual Plane Subtraction for Stitch Preparation**: Manually flattens images by selecting global planes using defined points.\n",
    "4. **Execution Example**: An example execution of the manual plane subtraction function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stitching ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Stitching Analysis\n",
    "\n",
    "This notebook demonstrates two methods for image stitching: one based on coordinate alignment and another using the `Stitch2D` library, which leverages feature-based alignment. The goal is to create a seamless composite image from a set of individual image tiles, useful for applications requiring a larger field of view, such as microscopy or aerial photography.\n",
    "\n",
    "The results of each stitching method will be saved in a dedicated folder named `stitching`, created within the main data folder. This allows easy access to both the original data and the stitched outputs for further analysis or visualization.\n",
    "\n",
    "- **Coordinate-Based Stitching:** This method relies on known positional information of each tile, ensuring that each image is placed at its correct location within the larger grid. It is particularly effective when precise coordinates are available and when error position is minimal.\n",
    "  \n",
    "- **Feature-Based Stitching (Stitch2D Library):** Using the `Stitch2D` library, this approach identifies and matches distinctive features between overlapping tiles, adjusting their placement to create a coherent whole. This method is highly adaptable to slight positional shifts or rotational differences between images, making it ideal for cases where precise coordinates are unavailable.\n",
    "\n",
    "The notebook provides a side-by-side comparison of the results from each method, allowing you to assess the relative effectiveness and quality of the final stitched image in both cases. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bachproces as bach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = r'your out flatten folder'\n",
    "\n",
    "# Stitching by Stitch2dMethod     \n",
    "bach.SimpleStitch2dMethod(PathPNGFiles = directorio,dimX = 4, downsample = 1,limit = None, from_placed = False)\n",
    "# Stitching by simple coordinate Method     \n",
    "bach.SimpleCoordinateMethod(PathXYZFiles = directorio,filas =3,columnas =16,nstd = 2)\n",
    "print('stiching end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bacteria Segmentation and Feature Mapping\n",
    "\n",
    "With the stitched image complete, the next step is to perform segmentation to identify individual bacteria within the image. This process uses a pre-trained YOLO model, which is well-suited for detecting and segmenting distinct objects within complex images. The segmentation results enable the creation of detailed feature maps, providing insights into various bacterial characteristics such as orientation, eccentricity, area, and density.\n",
    "\n",
    "The large volume of data generated during segmentation and analysis is managed using `.h5` files, which facilitate efficient memory handling and fast access to segmented regions. This data structure is particularly useful for handling high-resolution images or extensive datasets without running into memory limitations.\n",
    "\n",
    "By the end of this section, the notebook provides not only a segmented image but also comprehensive bacterial feature maps, supporting deeper analysis and quantitative assessments of bacterial distribution and morphology across the entire stitched image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation as seg\n",
    "from ultralytics import YOLO\n",
    "import segmentation_v3 as seg\n",
    "from skimage import exposure\n",
    "import os\n",
    "from datetime import datetime\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory and name of the image file to segment\n",
    "file_name = 'your_image.png'\n",
    "directori = r'your out flatten folder'\n",
    "image_path = os.path.join(directori, file_name)\n",
    "\n",
    "# Paths to save h5 and parameter files\n",
    "# Extract the name without extension and the original extension\n",
    "shortName, _ = os.path.splitext(file_name)\n",
    "# Get the current date and time in the desired format, including seconds\n",
    "fecha_actual = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "# Create the new file name with the tag and new extension\n",
    "prediction_h5 = f\"{'Prediction_'}{shortName}{fecha_actual}{'.h5'}\"\n",
    "prediction_nms_h5 = f\"{'Prediction_nms_'}{shortName}{fecha_actual}{'.h5'}\"\n",
    "parameters_txt = f\"{'Parameters_'}{shortName}{fecha_actual}{'.txt'}\"\n",
    "# Load a large image (example image)\n",
    "# Load the image with OpenCV (in BGR format)\n",
    "image_BGR = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Convert the image from BGR to RGB\n",
    "image_rgb = cv2.cvtColor(image_BGR, cv2.COLOR_BGR2RGB)\n",
    "# Convert grayscale to RGB by duplicating the grayscale channel across three channels\n",
    "# image_rgb = cv2.cvtColor(image_rgb, cv2.COLOR_GRAY2RGB)\n",
    "image_rgb = image_rgb.astype(np.float32)\n",
    "# Check if values are between 0 and 255; if so, normalize to [0, 1]\n",
    "if np.max(image_rgb) > 1:\n",
    "    image_normalized = image_rgb / 255.0  # Normalize to [0, 1]\n",
    "else:\n",
    "    image_normalized = image_rgb  # Already normalized\n",
    "\n",
    "height, width = image_normalized.shape[:2]\n",
    "\n",
    "np1 = max(height, width)      # Maximum number of pixels in the image\n",
    "lt = 14.3   # micrometers      # Size of the training image\n",
    "l1 = 1000/16                  # Size of the input image\n",
    "npx = int(np1 * lt / l1)      # Pixels used to crop the image\n",
    "patch_size = 640              # Patch size suitable for YOLO\n",
    "scale = patch_size / npx      # Scale to resize images\n",
    "overlap = 0.10  # Overlap size between patches as a percentage\n",
    "\n",
    "# List of images\n",
    "# image_normalized = exposure.equalize_hist(image_normalized)\n",
    "lista_imagenes, lista_pos, n_cuadros_x, n_cuadros_y, new_height, new_width = seg.dividir_imagen_en_cuadrados_con_solapamiento(image_normalized, npx, solapamiento=overlap)\n",
    "# seg.mostrar_subimagenes(lista_imagenes, n_cuadros_x, n_cuadros_y)\n",
    "\n",
    "model = YOLO('best_final.pt')  # Replace with the correct path to your best.pt file\n",
    "\n",
    "# Predict the list\n",
    "boxes_list, scores_list, pos_list = seg.PredictImagesList(prediction_h5, lista_imagenes,\n",
    "                                     lista_pos, scale, model, sigma=8, above_area_threshold=3000, below_area_threshold=550, conf=0.03, equalize=False, is_INTER_LANCZOS4=True)\n",
    "\n",
    "# g_mask = seg.combinar_mascaras_en_imagen('prediction_v2.h5', pos_list, round(new_height * scale) + 1, round(new_width * scale) + 1)\n",
    "# seg.show_image(g_mask)\n",
    "\n",
    "boxes, scores, pos = seg.apply_nms_list(prediction_h5, prediction_nms_h5, boxes_list, scores_list, pos_list, iou_threshold=0.4)\n",
    "print('Predicting')\n",
    "g_mask = seg.combinar_mascaras_en_imagen(prediction_nms_h5, pos, round(new_height * scale) + 1, round(new_width * scale) + 1)\n",
    "seg.show_image(g_mask)\n",
    "\n",
    "Maps = seg.DoPropertyMapAndTXT(prediction_nms_h5, parameters_txt, round(new_height * scale) + 1, round(new_width * scale) + 1)\n",
    "seg.show_image(Maps['Area'])\n",
    "\n",
    "# Create a custom colormap (red -> blue -> light gray -> green -> red)\n",
    "colors = [(1, 0, 0),   # Red for the minimum\n",
    "            (0, 0, 1),   # Blue for low intermediate values\n",
    "            (0, 0, 0),   # Light gray for zero\n",
    "            (0, 1, 0),   # Green for high intermediate values\n",
    "            (1, 0, 0)]   # Red for the maximum\n",
    "\n",
    "cmap_custom = LinearSegmentedColormap.from_list('custom_cmap', colors, N=256)\n",
    "\n",
    "# Create a modified colormap to show NaN (unsegmented pixels) in white\n",
    "cmap_custom.set_bad(color='white')\n",
    "\n",
    "plt.figure(figsize=(10, 10), dpi=120)  # Adjust the image window size if needed\n",
    "plt.imshow(Maps['Eccentricity'], cmap_custom)  # Adjust 'cmap' based on the image type (e.g., 'gray', 'viridis', etc.)\n",
    "plt.axis('off')  # Remove the axes\n",
    "plt.show()\n",
    "\n",
    "seg.show_image(Maps['Score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear el colormap personalizado (rojo -> azul -> gris claro -> verde -> rojo)\n",
    "colors = [(1, 0, 0),   # Rojo para el mínimo\n",
    "            (0, 1, 0),   # Azul para los valores bajos intermedios\n",
    "            (0.1, 1, 1),  # Gris claro para el cero\n",
    "            (0, 0, 1),   # Verde para los valores altos intermedios\n",
    "            (1, 0, 0)]   # Rojo para el máximo\n",
    "\n",
    "# colors = [(0.8, 0.4, 0.4),  # Rojo pastel para -90 grados\n",
    "#         (0.4, 0.4, 0.8),  # Azul pastel para -45 grados\n",
    "#         (0.7, 0.5, 0.7),  # Morado pastel para 0 grados\n",
    "#         (0.4, 0.8, 0.4),   # Verde pastel para 45 grados\n",
    "#         (0.8, 0.4, 0.4)    # Rojo pastel para 90 grados\n",
    "#     ]\n",
    "cmap_custom = LinearSegmentedColormap.from_list('custom_cmap', colors, N=256)\n",
    "\n",
    "# Crear un colormap modificado para mostrar NaN (píxeles no segmentados) en blanco\n",
    "cmap_custom.set_bad(color=\"white\")\n",
    "\n",
    "plt.figure(figsize=(10, 10), dpi=300)  # Ajusta el tamaño de la ventana de la imagen si es necesario\n",
    "#img = plt.imshow(Maps['Eccentricity'],vmin=0.6, vmax=1, cmap = 'gray')  # Puedes ajustar 'cmap' según el tipo de imagen (e.g., 'gray', 'viridis', etc.)\n",
    "# Selecciona un trozo de la matriz, por ejemplo, una sección de 1000x1000 píxeles\n",
    "sub_matrix = Maps['Orientation'][:, :]\n",
    "\n",
    "# Muestra solo el trozo seleccionado\n",
    "plt.imshow(sub_matrix, vmin=-3.1416/2, vmax=3.1416/2, cmap=cmap_custom)\n",
    "\n",
    "# Añadir la barra de color a la derecha\n",
    "#plt.colorbar(img)  # Mostrar la barra de color\n",
    "plt.axis('off')  # Quitar los ejes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flagella Visualization\n",
    "\n",
    "In this section, the notebook processes flattened XYZ files within a given folder to visualize flagella regions within the images. The workflow includes:\n",
    "\n",
    "1. **Loading Flattened XYZ Files:** Reads all flattened XYZ files from a specified folder, providing the data necessary for individual flagella analysis.\n",
    "  \n",
    "2. **Creating a Flagella Mask:** Generates a mask to isolate regions containing flagella, helping to focus on areas of interest.\n",
    "\n",
    "3. **Cropping and Flattening Individual Regions:** Each flagged region is cropped and undergoes individual flattening, ensuring a consistent visual representation across all regions.\n",
    "\n",
    "4. **Reconstructing and Saving the Flattened Image:** The cropped and flattened regions are then combined to form a single image, which is saved in PNG format with an appropriate color scale.\n",
    "\n",
    "5. **Stitching Flagella Images and Generating Statistics:** Following image reconstruction, flagella images are stitched together, and a summary text file is generated. This file includes comprehensive statistics on each segmented region, aiding in quantitative analysis.\n",
    "\n",
    "This section provides not only the visualized flagella image but also detailed statistical insights into the detected regions, supporting further study of flagella morphology and distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from typing import List, Tuple\n",
    "from AFMclasses import clImage, ChannelType, ExtentionType\n",
    "import managefiles as mgf\n",
    "import flattening_v2 as fla\n",
    "from scipy.ndimage import binary_dilation, binary_erosion\n",
    "from skimage.morphology import disk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import label, find_objects\n",
    "\n",
    "# Load image\n",
    "path = r'your out flatten folder'\n",
    "\n",
    "Areas_filename = 'Areas_filename.txt'\n",
    "higth_filename = 'higth_filename.txt'\n",
    "All_flatten_filename = 'out_flatten.xyz'\n",
    "umbral = 150e-9\n",
    "\n",
    "# Output folder\n",
    "outfolder = mgf.DoFolderWithDate('flagella')\n",
    "outpngfolder = os.path.join(outfolder, 'pngfolder')\n",
    "\n",
    "# Load images\n",
    "ImgList = mgf.LoadAllImageFile_fromDirectory(Directory=path, Exttype='.xyz')\n",
    "\n",
    "# Open the file once for all regions\n",
    "out_higth_file = os.path.join(outfolder, higth_filename)\n",
    "with open(out_higth_file, 'w') as higthfile:\n",
    "    output_file = os.path.join(outfolder, Areas_filename)\n",
    "    with open(output_file, 'w') as areafile:\n",
    "        # File header\n",
    "        areafile.write(\"index\\tregion\\tx_min\\ty_min\\tx_max\\ty_max\\tregion_area\\tflagella_area\\n\")\n",
    "        \n",
    "        # Iterate over each image\n",
    "        for index, Img in enumerate(ImgList):\n",
    "            # Display image\n",
    "            mgf.DisplayImage_with_scale(Img)\n",
    "            \n",
    "            # Make a copy\n",
    "            copi_img = copy.deepcopy(Img)\n",
    "            \n",
    "            # Create mask with threshold\n",
    "            mask = fla.MakeMaskWithThreshold(Img.matriz, umbral, area_minima=550, show=1)\n",
    "            \n",
    "            # Apply dilation and erosion\n",
    "            structuring_element = disk(6)\n",
    "            dilated_mask = binary_dilation(mask, structure=structuring_element)\n",
    "            dilated_mask = binary_erosion(dilated_mask, structure=structuring_element)\n",
    "\n",
    "            image = Img.matriz\n",
    "            output_flattened_image = np.zeros_like(image)  # Output matrix to store flattened regions\n",
    "            \n",
    "            # Detect connected regions in the mask\n",
    "            labeled_mask, num_features = label(dilated_mask)\n",
    "            regions = find_objects(labeled_mask)  # Get bounding boxes for each region\n",
    "            \n",
    "            # Crop and process each region\n",
    "            for i, bbox in enumerate(regions, start=1):\n",
    "                if bbox is not None:\n",
    "                    y_min, y_max = bbox[0].start, bbox[0].stop\n",
    "                    x_min, x_max = bbox[1].start, bbox[1].stop\n",
    "\n",
    "                    # Crop image and mask\n",
    "                    cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "                    cropped_mask = (labeled_mask[y_min:y_max, x_min:x_max] == i).astype(int)\n",
    "\n",
    "                    # Calculate area of the current region\n",
    "                    region_area = np.sum(cropped_mask)\n",
    "                    masked_image = cropped_image * cropped_mask\n",
    "\n",
    "                    # Flatten\n",
    "                    flatten, _ = fla.FlattenPlus_Mask(masked_image, mask=cropped_mask, perc=60)\n",
    "                    output_flattened_image[y_min:y_max, x_min:x_max] = flatten\n",
    "\n",
    "                    # Create flagella mask and calculate flagella area\n",
    "                    mask_fla = fla.MakeMaskWithThreshold(flatten, 15e-9, area_minima=0, show=0)\n",
    "                    flagella_area = np.sum(mask_fla == 0)\n",
    "\n",
    "                    # Save matrices\n",
    "                    fla.SaveMatriz(flatten, f'flatten_{index}_{i}.xyz', outfolder)\n",
    "                    fla.SaveMatriz(cropped_mask, f'cropped_mask_{index}_{i}.xyz', outfolder)\n",
    "                    fla.SaveMatriz(cropped_image, f'cropped_image_{index}_{i}.xyz', outfolder)\n",
    "                    fla.SaveMatriz(mask_fla, f'flagella_mask_{index}_{i}.xyz', outfolder)\n",
    "\n",
    "                    # Write coordinates and heights where mask is 1\n",
    "                    y_coords, x_coords = np.where(mask_fla == 0)\n",
    "                    heights = flatten[y_coords, x_coords]\n",
    "                    for x, y, height in zip(x_coords, y_coords, heights):\n",
    "                        higthfile.write(f\"{x + x_min} {y + y_min} {height}\\n\")  # Adjust global coordinates\n",
    "                    \n",
    "                    # Write image region coordinates and areas\n",
    "                    areafile.write(f\"{index}\\t{i}\\t{x_min}\\t{y_min}\\t{x_max}\\t{y_max}\\t{region_area}\\t{flagella_area}\\n\")\n",
    "            \n",
    "            if index == 0:\n",
    "                Norm = mgf.NormalizeNumpysOrclImages(output_flattened_image, nstd=4)\n",
    "\n",
    "            pngfile = os.path.splitext(Img.filename)[0]\n",
    "            mgf.SaveNumpyToPNG_By_PIL(output_flattened_image, outfolder, pngfile, norm=Norm, nstd=4, colormap='copper')\n",
    "            print('PNG file:', pngfile)\n",
    "        \n",
    "            copi_img.matriz = output_flattened_image\n",
    "            mgf.SaveImageToXYZ(copi_img, filename=f\"flatten_{os.path.splitext(Img.filename)[0]}.xyz\", path=outfolder)\n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
